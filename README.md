# Awesome Embodied AI

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of world models and vision-language-action models for robotics and embodied AI.

---

## Auto-Updated Paper Feeds

This repo automatically pulls new papers from arXiv twice daily (8am & 2pm PST):

- **[World Models Papers](digests/world_models.md)** - Papers matching "world model" and "world models"
- **[VLA Papers](digests/vla.md)** - Papers matching "VLA", "vision language action", and "vision-language-action"

Each feed shows papers from the last 2 days, with papers that have project pages or code highlighted at the top.

Want to run this yourself? See [SETUP.md](SETUP.md).

---

## Highlighted Papers

### World Models

| Paper | Authors | Links |
|-------|---------|-------|
| Odyssey-2 Pro | Odyssey | [Blog](https://odyssey.ml/the-gpt-2-moment-for-world-models) |

### Vision-Language-Action Models

| Paper | Authors | Links |
|-------|---------|-------|
| Cosmos Policy | NVIDIA | [arXiv](https://arxiv.org/abs/2601.16163) |

---

## Contributing

Found a paper or project that should be highlighted? Open a PR or issue!

## License

MIT
