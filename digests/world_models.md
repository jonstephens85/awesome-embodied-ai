# World Models

Papers on world models for robotics, video prediction, and simulation.

**Last updated:** 2026-01-29 16:43 UTC

**Papers found:** 8

[Back to Home](../README.md)

---

## Papers with Project Pages / Code

### [Advancing Open-source World Models](https://arxiv.org/abs/2601.20540v1)

**Authors:**  Robbyant Team, Zelin Gao, Qiuyu Wang, Yanhong Zeng, Jiapeng Zhu et al. (24 authors)

**Published:** 2026-01-28 | **Categories:** cs.CV

**Links:** [arXiv](https://arxiv.org/abs/2601.20540v1) | [PDF](https://arxiv.org/pdf/2601.20540v1.pdf) | [Project Page](https://technology.robbyant.com/lingbot-world) | [GitHub](https://github.com/robbyant/lingbot-world)

<details>
<summary>Abstract</summary>

We present LingBot-World, an open-sourced world simulator stemming from video generation. Positioned as a top-tier world model, LingBot-World offers the following features. (1) It maintains high fidelity and robust dynamics in a broad spectrum of environments, including realism, scientific contexts, cartoon styles, and beyond. (2) It enables a minute-level horizon while preserving contextual consistency over time, which is also known as "long-term memory". (3) It supports real-time interactivity...

</details>

---

### [Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models](https://arxiv.org/abs/2601.19834v1)

**Authors:** Jialong Wu, Xiaoying Zhang, Hongyi Yuan, Xiangcheng Zhang, Tianhao Huang et al. (10 authors)

**Published:** 2026-01-27 | **Categories:** cs.AI

**Links:** [arXiv](https://arxiv.org/abs/2601.19834v1) | [PDF](https://arxiv.org/pdf/2601.19834v1.pdf) | [Project Page](https://thuml.github.io/Reasoning-Visual-World)

<details>
<summary>Abstract</summary>

Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-level performance in formal and abstract domains such as mathematics and programming has been achieved in current systems by relying predominantly on verbal reasoning. However, they still lag far behind...

</details>

---

### [From Observations to Events: Event-Aware World Model for Reinforcement Learning](https://arxiv.org/abs/2601.19336v1)

**Authors:** Zhao-Han Peng, Shaohui Li, Zhi Li, Shulan Ruan, Yu Liu et al. (6 authors)

**Published:** 2026-01-27 | **Categories:** cs.LG, cs.AI

**Links:** [arXiv](https://arxiv.org/abs/2601.19336v1) | [PDF](https://arxiv.org/pdf/2601.19336v1.pdf) | [GitHub](https://github.com/MarquisDarwin/EAWM)

<details>
<summary>Abstract</summary>

While model-based reinforcement learning (MBRL) improves sample efficiency by learning world models from raw observations, existing methods struggle to generalize across structurally similar scenes and remain vulnerable to spurious variations such as textures or color shifts. From a cognitive science perspective, humans segment continuous sensory streams into discrete events and rely on these key events for decision-making. Motivated by this principle, we propose the Event-Aware World Model (EAW...

</details>

---

## Other Recent Papers

### [PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs](https://arxiv.org/abs/2601.20539v1)

**Authors:** Oguzhan Gungordu, Siheng Xiong, Faramarz Fekri

**Published:** 2026-01-28 | **Categories:** cs.AI, cs.CL

**Links:** [arXiv](https://arxiv.org/abs/2601.20539v1) | [PDF](https://arxiv.org/pdf/2601.20539v1.pdf)

<details>
<summary>Abstract</summary>

Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasoning about how new heuristics should be derived. We propose a novel multi-agent reasoning framework, referred to as Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs (Pat...

</details>

---

### [Distributional value gradients for stochastic environments](https://arxiv.org/abs/2601.20071v1)

**Authors:** Baptiste Debes, Tinne Tuytelaars

**Published:** 2026-01-27 | **Categories:** cs.LG

**Links:** [arXiv](https://arxiv.org/abs/2601.20071v1) | [PDF](https://arxiv.org/pdf/2601.20071v1.pdf)

<details>
<summary>Abstract</summary>

Gradient-regularized value learning methods improve sample efficiency by leveraging learned models of transition dynamics and rewards to estimate return gradients. However, existing approaches, such as MAGE, struggle in stochastic or noisy environments, limiting their applicability. In this work, we address these limitations by extending distributional reinforcement learning on continuous state-action spaces to model not only the distribution over scalar state-action value functions but also ove...

</details>

---

### [HARMONI: Multimodal Personalization of Multi-User Human-Robot Interactions with LLMs](https://arxiv.org/abs/2601.19839v1)

**Authors:** Jeanne Mal√©cot, Hamed Rahimi, Jeanne Cattoni, Marie Samson, Mouad Abrini et al. (8 authors)

**Published:** 2026-01-27 | **Categories:** cs.RO, cs.AI, cs.HC

**Links:** [arXiv](https://arxiv.org/abs/2601.19839v1) | [PDF](https://arxiv.org/pdf/2601.19839v1.pdf)

<details>
<summary>Abstract</summary>

Existing human-robot interaction systems often lack mechanisms for sustained personalization and dynamic adaptation in multi-user environments, limiting their effectiveness in real-world deployments. We present HARMONI, a multimodal personalization framework that leverages large language models to enable socially assistive robots to manage long-term multi-user interactions. The framework integrates four key modules: (i) a perception module that identifies active speakers and extracts multimodal ...

</details>

---

### [Agentic Design Patterns: A System-Theoretic Framework](https://arxiv.org/abs/2601.19752v1)

**Authors:** Minh-Dung Dao, Quy Minh Le, Hoang Thanh Lam, Duc-Trong Le, Quoc-Viet Pham et al. (7 authors)

**Published:** 2026-01-27 | **Categories:** cs.AI

**Links:** [arXiv](https://arxiv.org/abs/2601.19752v1) | [PDF](https://arxiv.org/pdf/2601.19752v1.pdf)

<details>
<summary>Abstract</summary>

With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introdu...

</details>

---

### [Dynamic Worlds, Dynamic Humans: Generating Virtual Human-Scene Interaction Motion in Dynamic Scenes](https://arxiv.org/abs/2601.19484v1)

**Authors:** Yin Wang, Zhiying Leng, Haitian Liu, Frederick W. B. Li, Mu Li et al. (6 authors)

**Published:** 2026-01-27 | **Categories:** cs.CV

**Links:** [arXiv](https://arxiv.org/abs/2601.19484v1) | [PDF](https://arxiv.org/pdf/2601.19484v1.pdf)

<details>
<summary>Abstract</summary>

Scenes are continuously undergoing dynamic changes in the real world. However, existing human-scene interaction generation methods typically treat the scene as static, which deviates from reality. Inspired by world models, we introduce Dyn-HSI, the first cognitive architecture for dynamic human-scene interaction, which endows virtual humans with three humanoid components. (1)Vision (human eyes): we equip the virtual human with a Dynamic Scene-Aware Navigation, which continuously perceives change...

</details>

---
