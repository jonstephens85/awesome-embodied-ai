# World Models

Papers on world models for robotics, video prediction, and simulation.

**Last updated:** 2026-02-05 22:17 UTC

**Papers found:** 12

[Back to Home](../README.md)

---

## Papers with Project Pages / Code

### [BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks](https://arxiv.org/abs/2602.03793v1)

**Authors:** Yixiang Chen, Peiyan Li, Jiabing Yang, Keji He, Xiangnan Wu et al. (11 authors)

**Published:** 2026-02-03 | **Categories:** cs.RO, cs.CV

**Links:** [arXiv](https://arxiv.org/abs/2602.03793v1) | [PDF](https://arxiv.org/pdf/2602.03793v1.pdf) | [Project Page](at)

<details>
<summary>Abstract</summary>

Embodied world models have emerged as a promising paradigm in robotics, most of which leverage large-scale Internet videos or pretrained video generation models to enrich visual and motion priors. However, they still face key challenges: a misalignment between coordinate-space actions and pixel-space videos, sensitivity to camera viewpoint, and non-unified architectures across embodiments. To this end, we present BridgeV2W, which converts coordinate-space actions into pixel-aligned embodiment ma...

</details>

---

### [A Lightweight Library for Energy-Based Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2602.03604v1)

**Authors:** Basile Terver, Randall Balestriero, Megi Dervishi, David Fan, Quentin Garrido et al. (11 authors)

**Published:** 2026-02-03 | **Categories:** cs.CV, cs.AI

**Links:** [arXiv](https://arxiv.org/abs/2602.03604v1) | [PDF](https://arxiv.org/pdf/2602.03604v1.pdf) | [GitHub](https://github.com/facebookresearch/eb_jepa)

<details>
<summary>Abstract</summary>

We present EB-JEPA, an open-source library for learning representations and world models using Joint-Embedding Predictive Architectures (JEPAs). JEPAs learn to predict in representation space rather than pixel space, avoiding the pitfalls of generative modeling while capturing semantically meaningful features suitable for downstream tasks. Our library provides modular, self-contained implementations that illustrate how representation learning techniques developed for image-level self-supervised ...

</details>

---

### [InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation](https://arxiv.org/abs/2602.03242v1)

**Authors:** Zhuoran Yang, Xi Guo, Chenjing Ding, Chiyu Wang, Wei Wu et al. (6 authors)

**Published:** 2026-02-03 | **Categories:** cs.CV

**Links:** [arXiv](https://arxiv.org/abs/2602.03242v1) | [PDF](https://arxiv.org/pdf/2602.03242v1.pdf) | [Project Page](is)

<details>
<summary>Abstract</summary>

Autonomous driving relies on robust models trained on high-quality, large-scale multi-view driving videos. While world models offer a cost-effective solution for generating realistic driving videos, they struggle to maintain instance-level temporal consistency and spatial geometric fidelity. To address these challenges, we propose InstaDrive, a novel framework that enhances driving video realism through two key advancements: (1) Instance Flow Guider, which extracts and propagates instance featur...

</details>

---

### [ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask](https://arxiv.org/abs/2602.03213v1)

**Authors:** Zhuoran Yang, Yanyong Zhang

**Published:** 2026-02-03 | **Categories:** cs.CV

**Links:** [arXiv](https://arxiv.org/abs/2602.03213v1) | [PDF](https://arxiv.org/pdf/2602.03213v1.pdf) | [Project Page](is)

<details>
<summary>Abstract</summary>

Autonomous driving relies on robust models trained on large-scale, high-quality multi-view driving videos. Although world models provide a cost-effective solution for generating realistic driving data, they often suffer from identity drift, where the same object changes its appearance or category across frames due to the absence of instance-level temporal constraints. We introduce ConsisDrive, an identity-preserving driving world model designed to enforce temporal consistency at the instance lev...

</details>

---

## Other Recent Papers

### [Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning](https://arxiv.org/abs/2602.04821v1)

**Authors:** Joydeep Chandra, Satyam Kumar Navneet, Aleksandr Algazinov, Yong Zhang

**Published:** 2026-02-04 | **Categories:** cs.LG, cs.AI

**Links:** [arXiv](https://arxiv.org/abs/2602.04821v1) | [PDF](https://arxiv.org/pdf/2602.04821v1.pdf)

<details>
<summary>Abstract</summary>

Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically reweight graph attention via confidence-monotonic attention, achieving distribution-free coverage guaran...

</details>

---

### [Dual Mind World Model Inspired Network Digital Twin for Access Scheduling](https://arxiv.org/abs/2602.04566v1)

**Authors:** Hrishikesh Dutta, Roberto Minerva, Noel Crespi

**Published:** 2026-02-04 | **Categories:** cs.NI, cs.AI, cs.MA

**Links:** [arXiv](https://arxiv.org/abs/2602.04566v1) | [PDF](https://arxiv.org/pdf/2602.04566v1.pdf)

<details>
<summary>Abstract</summary>

Emerging networked systems such as industrial IoT and real-time cyber-physical infrastructures demand intelligent scheduling strategies capable of adapting to dynamic traffic, deadlines, and interference constraints. In this work, we present a novel Digital Twin-enabled scheduling framework inspired by Dual Mind World Model (DMWM) architecture, for learning-informed and imagination-driven network control. Unlike conventional rule-based or purely data-driven policies, the proposed DMWM combines s...

</details>

---

### [Language Models Struggle to Use Representations Learned In-Context](https://arxiv.org/abs/2602.04212v1)

**Authors:** Michael A. Lepori, Tal Linzen, Ann Yuan, Katja Filippova

**Published:** 2026-02-04 | **Categories:** cs.CL, cs.AI

**Links:** [arXiv](https://arxiv.org/abs/2602.04212v1) | [PDF](https://arxiv.org/pdf/2602.04212v1.pdf)

<details>
<summary>Abstract</summary>

Though large language models (LLMs) have enabled great success across a wide variety of tasks, they still appear to fall short of one of the loftier goals of artificial intelligence research: creating an artificial system that can adapt its behavior to radically new contexts upon deployment. One important step towards this goal is to create systems that can induce rich representations of data that are seen in-context, and then flexibly deploy these representations to accomplish goals. Recently, ...

</details>

---

### [Active Epistemic Control for Query-Efficient Verified Planning](https://arxiv.org/abs/2602.03974v1)

**Authors:** Shuhui Qu

**Published:** 2026-02-03 | **Categories:** cs.AI

**Links:** [arXiv](https://arxiv.org/abs/2602.03974v1) | [PDF](https://arxiv.org/pdf/2602.03974v1.pdf)

<details>
<summary>Abstract</summary>

Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world models can cheaply predict missing facts, but prediction errors can silently induce infeasible commitments. We present \textbf{Active Epistemic Control (AEC)}, an epistemic-categorical planning layer that integrates model-based belief management wit...

</details>

---

### [LIVE: Long-horizon Interactive Video World Modeling](https://arxiv.org/abs/2602.03747v1)

**Authors:** Junchao Huang, Ziyang Ye, Xinting Hu, Tianyu He, Guiyu Zhang et al. (8 authors)

**Published:** 2026-02-03 | **Categories:** cs.CV

**Links:** [arXiv](https://arxiv.org/abs/2602.03747v1) | [PDF](https://arxiv.org/pdf/2602.03747v1.pdf)

<details>
<summary>Abstract</summary>

Autoregressive video world models predict future visual observations conditioned on actions. While effective over short horizons, these models often struggle with long-horizon generation, as small prediction errors accumulate over time. Prior methods alleviate this by introducing pre-trained teacher models and sequence-level distribution matching, which incur additional computational cost and fail to prevent error propagation beyond the training horizon. In this work, we propose LIVE, a Long-hor...

</details>

---

### [EHRWorld: A Patient-Centric Medical World Model for Long-Horizon Clinical Trajectories](https://arxiv.org/abs/2602.03569v1)

**Authors:** Linjie Mu, Zhongzhen Huang, Yannian Gu, Shengqian Qin, Shaoting Zhang et al. (6 authors)

**Published:** 2026-02-03 | **Categories:** cs.AI, cs.LG

**Links:** [arXiv](https://arxiv.org/abs/2602.03569v1) | [PDF](https://arxiv.org/pdf/2602.03569v1.pdf)

<details>
<summary>Abstract</summary>

World models offer a principled framework for simulating future states under interventions, but realizing such models in complex, high-stakes domains like medicine remains challenging. Recent large language models (LLMs) have achieved strong performance on static medical reasoning tasks, raising the question of whether they can function as dynamic medical world models capable of simulating disease progression and treatment outcomes over time. In this work, we show that LLMs only incorporating me...

</details>

---

### [A Minimal Task Reveals Emergent Path Integration and Object-Location Binding in a Predictive Sequence Model](https://arxiv.org/abs/2602.03490v1)

**Authors:** Linda Ariel Ventura, Victoria Bosch, Tim C Kietzmann, Sushrut Thorat

**Published:** 2026-02-03 | **Categories:** cs.LG, q-bio.NC

**Links:** [arXiv](https://arxiv.org/abs/2602.03490v1) | [PDF](https://arxiv.org/pdf/2602.03490v1.pdf)

<details>
<summary>Abstract</summary>

Adaptive cognition requires structured internal models representing objects and their relations. Predictive neural networks are often proposed to form such "world models", yet their underlying mechanisms remain unclear. One hypothesis is that action-conditioned sequential prediction suffices for learning such world models. In this work, we investigate this possibility in a minimal in-silico setting. Sequentially sampling tokens from 2D continuous token scenes, a recurrent neural network is train...

</details>

---

### [General Agents Contain World Models, even under Partial Observability and Stochasticity](https://arxiv.org/abs/2602.03146v1)

**Authors:** Santiago Cifuentes

**Published:** 2026-02-03 | **Categories:** cs.AI

**Links:** [arXiv](https://arxiv.org/abs/2602.03146v1) | [PDF](https://arxiv.org/pdf/2602.03146v1.pdf)

<details>
<summary>Abstract</summary>

Deciding whether an agent possesses a model of its surrounding world is a fundamental step toward understanding its capabilities and limitations. In [10], it was shown that, within a particular framework, every almost optimal and general agent necessarily contains sufficient knowledge of its environment to allow an approximate reconstruction of it by querying the agent as a black box. This result relied on the assumptions that the agent is deterministic and that the environment is fully observab...

</details>

---
